{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "40f0e59b",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "---\n",
    "\n",
    "## **1. What are Regression Metrics?**\n",
    "\n",
    "**Definition:**\n",
    "Regression metrics are quantitative measures used to evaluate how well a regression model predicts **continuous outcomes** (numerical values). They compare predicted values (**ŷ**) to actual values (**y**) and give a score that reflects prediction accuracy and reliability.\n",
    "\n",
    "**Role in Model Assessment:**\n",
    "\n",
    "* Measure **accuracy** of predictions.\n",
    "* Identify if the model is **overfitting** or **underfitting**.\n",
    "* Compare performance of multiple models.\n",
    "* Guide model improvements (feature engineering, tuning).\n",
    "\n",
    "**Importance:**\n",
    "Without these metrics, you can’t objectively say whether your model is “good.” A model might *look* okay when plotted, but metrics give you a **clear numeric performance measure**.\n",
    "\n",
    "---\n",
    "\n",
    "## **2. Types of Regression Metrics**\n",
    "\n",
    "We’ll cover **MAE, MSE, RMSE, R², and Adjusted R²**.\n",
    "\n",
    "---\n",
    "\n",
    "### **2.1 Mean Absolute Error (MAE)**\n",
    "\n",
    "**Definition:**\n",
    "The **average of the absolute differences** between actual and predicted values.\n",
    "\n",
    "$$\n",
    "\\text{MAE} = \\frac{1}{n} \\sum_{i=1}^{n} |y_i - \\hat{y}_i|\n",
    "$$\n",
    "\n",
    "**Purpose:**\n",
    "\n",
    "* Measures **average magnitude** of errors, without considering direction.\n",
    "* Easy to understand (in same units as target variable).\n",
    "\n",
    "**Interpretation:**\n",
    "\n",
    "* Lower MAE → better performance.\n",
    "* Example: MAE = 5 means predictions are off by 5 units **on average**.\n",
    "\n",
    "**Use cases:**\n",
    "\n",
    "* When you want a simple, interpretable measure.\n",
    "* When **outliers are not a big concern**.\n",
    "* **Limitations:** Doesn’t heavily penalize large errors.\n",
    "\n",
    "**Example:**\n",
    "If actual house prices are \\[200, 220, 250] and predicted prices are \\[210, 225, 245]:\n",
    "\n",
    "$$\n",
    "\\text{MAE} = \\frac{|200-210| + |220-225| + |250-245|}{3} = \\frac{10+5+5}{3} = 6.67\n",
    "$$\n",
    "\n",
    "---\n",
    "\n",
    "### **2.2 Mean Squared Error (MSE)**\n",
    "\n",
    "**Definition:**\n",
    "The **average of squared differences** between actual and predicted values.\n",
    "\n",
    "$$\n",
    "\\text{MSE} = \\frac{1}{n} \\sum_{i=1}^{n} (y_i - \\hat{y}_i)^2\n",
    "$$\n",
    "\n",
    "**Purpose:**\n",
    "\n",
    "* Similar to MAE but **penalizes large errors more** (squaring effect).\n",
    "* Useful when large deviations are undesirable.\n",
    "\n",
    "**Interpretation:**\n",
    "\n",
    "* Lower MSE → better performance.\n",
    "* Not in same units as target variable (units are squared).\n",
    "\n",
    "**Use cases:**\n",
    "\n",
    "* When you care about **penalizing big errors**.\n",
    "* Often used in optimization during model training.\n",
    "* **Limitations:** Can be skewed by outliers.\n",
    "\n",
    "**Example:**\n",
    "Using same data: Errors are \\[-10, -5, 5] → Squared errors = \\[100, 25, 25] → MSE = (100+25+25)/3 = 50.\n",
    "\n",
    "---\n",
    "\n",
    "### **2.3 Root Mean Squared Error (RMSE)**\n",
    "\n",
    "**Definition:**\n",
    "The **square root of MSE**, bringing it back to original units.\n",
    "\n",
    "$$\n",
    "\\text{RMSE} = \\sqrt{\\frac{1}{n} \\sum_{i=1}^{n} (y_i - \\hat{y}_i)^2}\n",
    "$$\n",
    "\n",
    "**Purpose:**\n",
    "\n",
    "* Easy to interpret (same units as target variable).\n",
    "* Still penalizes large errors more than small ones.\n",
    "\n",
    "**Interpretation:**\n",
    "\n",
    "* Lower RMSE → better.\n",
    "* RMSE is always ≥ MAE (because squaring increases error magnitude).\n",
    "\n",
    "**Use cases:**\n",
    "\n",
    "* When you want to interpret errors in actual units **and** penalize big mistakes.\n",
    "* **Limitations:** Outlier-sensitive.\n",
    "\n",
    "**Example:**\n",
    "From MSE = 50, RMSE = √50 ≈ 7.07.\n",
    "\n",
    "---\n",
    "\n",
    "### **2.4 R-squared (R²)**\n",
    "\n",
    "**Definition:**\n",
    "The proportion of variance in the target variable explained by the model.\n",
    "\n",
    "$$\n",
    "R^2 = 1 - \\frac{\\sum (y_i - \\hat{y}_i)^2}{\\sum (y_i - \\bar{y})^2}\n",
    "$$\n",
    "\n",
    "Where $\\bar{y}$ is the mean of actual values.\n",
    "\n",
    "**Purpose:**\n",
    "\n",
    "* Measures **goodness of fit**.\n",
    "* Explains how much of the variation in target is explained by predictors.\n",
    "\n",
    "**Interpretation:**\n",
    "\n",
    "* Range: 0 to 1 (sometimes negative if model is worse than baseline mean prediction).\n",
    "* Higher R² → better fit.\n",
    "* Example: R² = 0.85 means model explains **85% of variance** in the data.\n",
    "\n",
    "**Use cases:**\n",
    "\n",
    "* Understanding model’s explanatory power.\n",
    "* **Limitations:** High R² doesn’t always mean good predictions; can be artificially high with more features.\n",
    "\n",
    "**Example:**\n",
    "If the sum of squared residuals (SSR) = 50 and total sum of squares (TSS) = 200:\n",
    "R² = 1 - (50/200) = 0.75 → 75% of variance explained.\n",
    "\n",
    "---\n",
    "\n",
    "### **2.5 Adjusted R-squared**\n",
    "\n",
    "**Definition:**\n",
    "A modified version of R² that adjusts for the number of predictors.\n",
    "\n",
    "$$\n",
    "\\text{Adjusted R}^2 = 1 - \\left( \\frac{(1 - R^2)(n-1)}{n - p - 1} \\right)\n",
    "$$\n",
    "\n",
    "Where:\n",
    "\n",
    "* $n$ = number of observations\n",
    "* $p$ = number of predictors\n",
    "\n",
    "**Purpose:**\n",
    "\n",
    "* Prevents **overestimation** of goodness of fit when adding unnecessary variables.\n",
    "\n",
    "**Interpretation:**\n",
    "\n",
    "* Can be lower than R² if added predictors don’t improve model.\n",
    "* If Adjusted R² increases → new variable improved the model.\n",
    "\n",
    "**Use cases:**\n",
    "\n",
    "* Comparing models with different numbers of predictors.\n",
    "* **Limitations:** Not suitable for non-linear models without adaptation.\n",
    "\n",
    "---\n",
    "\n",
    "## **3. Choosing the Right Metric**\n",
    "\n",
    "| Scenario                                      | Best Metric      | Why                            |\n",
    "| --------------------------------------------- | ---------------- | ------------------------------ |\n",
    "| Easy interpretation, no strong outlier effect | MAE              | Simple, clear meaning          |\n",
    "| Penalize large errors heavily                 | MSE / RMSE       | Squaring effect                |\n",
    "| Compare fit quality between models            | R² / Adjusted R² | Shows explained variance       |\n",
    "| Avoid overfitting in multiple predictors      | Adjusted R²      | Penalizes unnecessary features |\n",
    "\n",
    "---\n",
    "\n",
    "## **4. Common Pitfalls**\n",
    "\n",
    "* **Only using R²:** High R² can hide poor predictions if dataset has outliers.\n",
    "* **Ignoring scale:** MSE and RMSE are scale-dependent; comparing across different datasets can be misleading.\n",
    "* **Overfitting check:** A huge difference between training and test metric means model might be overfitting.\n",
    "\n",
    "---\n",
    "\n",
    "## **5. Practical Example (Python)**\n",
    "\n",
    "```python\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "import numpy as np\n",
    "\n",
    "# Actual and predicted values\n",
    "y_true = np.array([200, 220, 250, 270, 300])\n",
    "y_pred = np.array([210, 225, 245, 280, 295])\n",
    "\n",
    "# MAE\n",
    "mae = mean_absolute_error(y_true, y_pred)\n",
    "\n",
    "# MSE\n",
    "mse = mean_squared_error(y_true, y_pred)\n",
    "\n",
    "# RMSE\n",
    "rmse = np.sqrt(mse)\n",
    "\n",
    "# R2\n",
    "r2 = r2_score(y_true, y_pred)\n",
    "\n",
    "print(f\"MAE: {mae:.2f}\")\n",
    "print(f\"MSE: {mse:.2f}\")\n",
    "print(f\"RMSE: {rmse:.2f}\")\n",
    "print(f\"R²: {r2:.2f}\")\n",
    "```\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f985a09",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
